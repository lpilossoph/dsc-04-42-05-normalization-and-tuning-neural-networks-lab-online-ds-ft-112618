{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization and Tuning Neural Networks - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "For this lab on initialization and optimization, let's look at a slightly different type of neural network. This time, we will not perform a classification task as we've done before (Santa vs not santa, bank complaint types), but we'll look at a linear regression problem.\n",
    "\n",
    "We can just as well use deep learning networks for linear regression as for a classification problem. Do note that getting regression to work with neural networks is a hard problem because the output is unbounded ($\\hat y$ can technically range from $-\\infty$ to $+\\infty$, and the models are especially prone to exploding gradients. This issue makes a regression exercise the perfect learning case!\n",
    "\n",
    "## Objectives\n",
    "You will be able to:\n",
    "* Build a nueral network using keras\n",
    "* Normalize your data to assist algorithm convergence\n",
    "* Implement and observe the impact of various initialization techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras import initializers\n",
    "from keras import layers\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "from keras import optimizers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we'll be working with is data related to facebook posts published during the year of 2014 on the Facebook's page of a renowned cosmetics brand.  It includes 7 features known prior to post publication, and 12 features for evaluating the post impact. What we want to do is make a predictor for the number of \"likes\" for a post, taking into account the 7 features prior to posting.\n",
    "\n",
    "First, let's import the data set and delete any rows with missing data. Afterwards, briefly preview the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; load the dataset and drop rows with missing values. Then preview the data.\n",
    "df = pd.read_csv('dataset_Facebook.csv', sep=';', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of      Page total likes    Type  Category  Post Month  Post Weekday  Post Hour  \\\n",
      "0              139441   Photo         2          12             4          3   \n",
      "1              139441  Status         2          12             3         10   \n",
      "2              139441   Photo         3          12             3          3   \n",
      "3              139441   Photo         2          12             2         10   \n",
      "4              139441   Photo         2          12             2          3   \n",
      "5              139441  Status         2          12             1          9   \n",
      "6              139441   Photo         3          12             1          3   \n",
      "7              139441   Photo         3          12             7          9   \n",
      "8              139441  Status         2          12             7          3   \n",
      "9              139441   Photo         3          12             6         10   \n",
      "10             139441  Status         2          12             5         10   \n",
      "11             139441   Photo         2          12             5         10   \n",
      "12             139441   Photo         2          12             5         10   \n",
      "13             139441   Photo         2          12             5          3   \n",
      "14             138414   Photo         2          12             4          5   \n",
      "15             138414  Status         2          12             3         10   \n",
      "16             138414   Photo         3          12             3          3   \n",
      "17             138414   Photo         1          12             2         12   \n",
      "18             138414  Status         3          12             2          3   \n",
      "19             138414   Photo         3          12             1         11   \n",
      "20             138414   Photo         2          12             1          3   \n",
      "21             138414   Photo         1          12             7         10   \n",
      "22             138414    Link         1          12             7         10   \n",
      "23             138414   Photo         3          12             7          3   \n",
      "24             138414  Status         2          12             6         10   \n",
      "25             138458  Status         2          12             6          3   \n",
      "26             138458  Status         2          12             5         11   \n",
      "27             138458   Photo         3          12             5          3   \n",
      "28             138895   Photo         2          12             5          3   \n",
      "29             138895   Video         1          12             4         11   \n",
      "..                ...     ...       ...         ...           ...        ...   \n",
      "469             91544   Photo         3           2             4          3   \n",
      "470             91437    Link         1           2             3         13   \n",
      "471             91330   Photo         3           2             3          3   \n",
      "472             91223   Photo         1           2             2         13   \n",
      "473             91116   Photo         3           2             2          4   \n",
      "474             91009   Photo         1           2             1         12   \n",
      "475             86909   Photo         3           1             6         16   \n",
      "476             86909   Photo         1           1             6         10   \n",
      "477             86909    Link         1           1             6          4   \n",
      "478             86909   Photo         3           1             5         13   \n",
      "479             86909   Photo         3           1             5          4   \n",
      "480             86909   Photo         2           1             4         11   \n",
      "481             86491    Link         1           1             4          4   \n",
      "482             86491   Photo         3           1             3         10   \n",
      "483             86491   Photo         2           1             3          3   \n",
      "484             86491   Photo         3           1             2          7   \n",
      "485             86491    Link         1           1             2          2   \n",
      "486             85979   Photo         3           1             1         12   \n",
      "487             85979   Photo         3           1             1          2   \n",
      "488             85979   Photo         3           1             7         10   \n",
      "489             85979   Photo         3           1             7          2   \n",
      "490             85979   Photo         3           1             6         11   \n",
      "491             85979   Photo         3           1             6          3   \n",
      "492             85979    Link         1           1             5         11   \n",
      "493             85093   Photo         3           1             1          2   \n",
      "494             85093   Photo         3           1             7         10   \n",
      "495             85093   Photo         3           1             7          2   \n",
      "496             81370   Photo         2           1             5          8   \n",
      "497             81370   Photo         1           1             5          2   \n",
      "498             81370   Photo         3           1             4         11   \n",
      "\n",
      "     Paid  Lifetime Post Total Reach  Lifetime Post Total Impressions  \\\n",
      "0     0.0                       2752                             5091   \n",
      "1     0.0                      10460                            19057   \n",
      "2     0.0                       2413                             4373   \n",
      "3     1.0                      50128                            87991   \n",
      "4     0.0                       7244                            13594   \n",
      "5     0.0                      10472                            20849   \n",
      "6     1.0                      11692                            19479   \n",
      "7     1.0                      13720                            24137   \n",
      "8     0.0                      11844                            22538   \n",
      "9     0.0                       4694                             8668   \n",
      "10    0.0                      21744                            42334   \n",
      "11    0.0                       3112                             5590   \n",
      "12    0.0                       2847                             5133   \n",
      "13    0.0                       2549                             4896   \n",
      "14    1.0                      22784                            39941   \n",
      "15    0.0                      10060                            19680   \n",
      "16    0.0                       1722                             2981   \n",
      "17    1.0                      53264                           111785   \n",
      "18    0.0                       3930                             7509   \n",
      "19    0.0                       1591                             2825   \n",
      "20    0.0                       2848                             5066   \n",
      "21    0.0                       1384                             2467   \n",
      "22    0.0                       3454                             6853   \n",
      "23    0.0                       2723                             4888   \n",
      "24    0.0                       8488                            15294   \n",
      "25    0.0                       8284                            15104   \n",
      "26    0.0                      19552                            34143   \n",
      "27    0.0                       2478                             4306   \n",
      "28    0.0                       9560                            18264   \n",
      "29    1.0                      36208                            61262   \n",
      "..    ...                        ...                              ...   \n",
      "469   0.0                       9528                            16779   \n",
      "470   0.0                       9356                            14986   \n",
      "471   0.0                       7732                            13264   \n",
      "472   0.0                       5240                             8893   \n",
      "473   1.0                       7132                            12060   \n",
      "474   0.0                      21928                            39641   \n",
      "475   1.0                       5754                             9238   \n",
      "476   1.0                      37088                            10966   \n",
      "477   0.0                      39600                             7927   \n",
      "478   0.0                       5536                             8745   \n",
      "479   0.0                       6056                            10325   \n",
      "480   0.0                      11484                            20696   \n",
      "481   1.0                       4938                             7910   \n",
      "482   0.0                      66784                             9456   \n",
      "483   0.0                       5526                             8779   \n",
      "484   0.0                       5040                             8367   \n",
      "485   0.0                       5168                             8371   \n",
      "486   0.0                       5034                             8030   \n",
      "487   0.0                       4908                             7491   \n",
      "488   0.0                       9700                            17442   \n",
      "489   0.0                       4800                             7754   \n",
      "490   0.0                       5280                             8703   \n",
      "491   1.0                       6184                            10228   \n",
      "492   0.0                      45920                             5808   \n",
      "493   0.0                       8412                            13960   \n",
      "494   0.0                       5400                             9218   \n",
      "495   0.0                       4684                             7536   \n",
      "496   0.0                       3480                             6229   \n",
      "497   0.0                       3778                             7216   \n",
      "498   0.0                       4156                             7564   \n",
      "\n",
      "     Lifetime Engaged Users  Lifetime Post Consumers  \\\n",
      "0                       178                      109   \n",
      "1                      1457                     1361   \n",
      "2                       177                      113   \n",
      "3                      2211                      790   \n",
      "4                       671                      410   \n",
      "5                      1191                     1073   \n",
      "6                       481                      265   \n",
      "7                       537                      232   \n",
      "8                      1530                     1407   \n",
      "9                       280                      183   \n",
      "10                     4258                     4100   \n",
      "11                      208                      127   \n",
      "12                      193                      115   \n",
      "13                      249                      134   \n",
      "14                      887                      337   \n",
      "15                     1264                     1209   \n",
      "16                      163                      123   \n",
      "17                     1706                     1103   \n",
      "18                      130                       86   \n",
      "19                      121                       88   \n",
      "20                      200                      142   \n",
      "21                       15                       15   \n",
      "22                      118                      104   \n",
      "23                      176                      118   \n",
      "24                     1341                     1270   \n",
      "25                     1521                     1462   \n",
      "26                     2806                     2531   \n",
      "27                      212                      124   \n",
      "28                      973                      559   \n",
      "29                     1141                     1068   \n",
      "..                      ...                      ...   \n",
      "469                    1245                     1175   \n",
      "470                     448                      381   \n",
      "471                    1066                     1002   \n",
      "472                     857                      837   \n",
      "473                    1004                      944   \n",
      "474                    1512                     1479   \n",
      "475                    1179                     1143   \n",
      "476                    2728                     2288   \n",
      "477                     572                      496   \n",
      "478                    1141                     1099   \n",
      "479                    1117                     1078   \n",
      "480                    1762                     1635   \n",
      "481                      66                       63   \n",
      "482                    2969                     2833   \n",
      "483                    1096                     1058   \n",
      "484                    1062                     1023   \n",
      "485                      66                       59   \n",
      "486                    1020                      993   \n",
      "487                     957                      937   \n",
      "488                    1407                     1271   \n",
      "489                     975                      938   \n",
      "490                     951                      911   \n",
      "491                     956                      901   \n",
      "492                     753                      655   \n",
      "493                    1179                     1111   \n",
      "494                     810                      756   \n",
      "495                     733                      708   \n",
      "496                     537                      508   \n",
      "497                     625                      572   \n",
      "498                     626                      574   \n",
      "\n",
      "     Lifetime Post Consumptions  \\\n",
      "0                           159   \n",
      "1                          1674   \n",
      "2                           154   \n",
      "3                          1119   \n",
      "4                           580   \n",
      "5                          1389   \n",
      "6                           364   \n",
      "7                           305   \n",
      "8                          1692   \n",
      "9                           250   \n",
      "10                         4540   \n",
      "11                          145   \n",
      "12                          133   \n",
      "13                          168   \n",
      "14                          417   \n",
      "15                         1425   \n",
      "16                          148   \n",
      "17                         1655   \n",
      "18                          112   \n",
      "19                          111   \n",
      "20                          184   \n",
      "21                           20   \n",
      "22                          130   \n",
      "23                          143   \n",
      "24                         1489   \n",
      "25                         1711   \n",
      "26                         3420   \n",
      "27                          149   \n",
      "28                          885   \n",
      "29                         1728   \n",
      "..                          ...   \n",
      "469                        1725   \n",
      "470                         505   \n",
      "471                        1336   \n",
      "472                        1020   \n",
      "473                        1226   \n",
      "474                        1837   \n",
      "475                        1452   \n",
      "476                        3183   \n",
      "477                         581   \n",
      "478                        1461   \n",
      "479                        1427   \n",
      "480                        2741   \n",
      "481                          70   \n",
      "482                        3645   \n",
      "483                        1399   \n",
      "484                        1348   \n",
      "485                          71   \n",
      "486                        1243   \n",
      "487                        1153   \n",
      "488                        2007   \n",
      "489                        1278   \n",
      "490                        1237   \n",
      "491                        1140   \n",
      "492                         763   \n",
      "493                        1632   \n",
      "494                        1003   \n",
      "495                         985   \n",
      "496                         687   \n",
      "497                         795   \n",
      "498                         832   \n",
      "\n",
      "     Lifetime Post Impressions by people who have liked your Page  \\\n",
      "0                                                 3078              \n",
      "1                                                11710              \n",
      "2                                                 2812              \n",
      "3                                                61027              \n",
      "4                                                 6228              \n",
      "5                                                16034              \n",
      "6                                                15432              \n",
      "7                                                19728              \n",
      "8                                                15220              \n",
      "9                                                 4309              \n",
      "10                                               37849              \n",
      "11                                                3887              \n",
      "12                                                3779              \n",
      "13                                                3631              \n",
      "14                                               34415              \n",
      "15                                               17272              \n",
      "16                                                1868              \n",
      "17                                               92512              \n",
      "18                                                5009              \n",
      "19                                                2116              \n",
      "20                                                3561              \n",
      "21                                                2196              \n",
      "22                                                6282              \n",
      "23                                                2964              \n",
      "24                                                9684              \n",
      "25                                               10266              \n",
      "26                                               17748              \n",
      "27                                                2612              \n",
      "28                                                9217              \n",
      "29                                               30131              \n",
      "..                                                 ...              \n",
      "469                                              11885              \n",
      "470                                              13919              \n",
      "471                                               8753              \n",
      "472                                               7420              \n",
      "473                                               8294              \n",
      "474                                               6338              \n",
      "475                                               6101              \n",
      "476                                              66311              \n",
      "477                                              12522              \n",
      "478                                               5225              \n",
      "479                                               6823              \n",
      "480                                               8774              \n",
      "481                                               6625              \n",
      "482                                              17809              \n",
      "483                                               5732              \n",
      "484                                               5485              \n",
      "485                                               7041              \n",
      "486                                               5340              \n",
      "487                                               4642              \n",
      "488                                               8872              \n",
      "489                                               4932              \n",
      "490                                               5757              \n",
      "491                                               6085              \n",
      "492                                              15766              \n",
      "493                                               8632              \n",
      "494                                               5654              \n",
      "495                                               4750              \n",
      "496                                               3961              \n",
      "497                                               4742              \n",
      "498                                               4534              \n",
      "\n",
      "     Lifetime Post reach by people who like your Page  \\\n",
      "0                                                1640   \n",
      "1                                                6112   \n",
      "2                                                1503   \n",
      "3                                               32048   \n",
      "4                                                3200   \n",
      "5                                                7852   \n",
      "6                                                9328   \n",
      "7                                               11056   \n",
      "8                                                7912   \n",
      "9                                                2324   \n",
      "10                                              18952   \n",
      "11                                               2174   \n",
      "12                                               2072   \n",
      "13                                               1917   \n",
      "14                                              19312   \n",
      "15                                               8548   \n",
      "16                                               1050   \n",
      "17                                              39776   \n",
      "18                                               2410   \n",
      "19                                               1161   \n",
      "20                                               1963   \n",
      "21                                               1172   \n",
      "22                                               3100   \n",
      "23                                               1621   \n",
      "24                                               5244   \n",
      "25                                               5372   \n",
      "26                                               9824   \n",
      "27                                               1443   \n",
      "28                                               4748   \n",
      "29                                              14112   \n",
      "..                                                ...   \n",
      "469                                              6672   \n",
      "470                                              8460   \n",
      "471                                              4880   \n",
      "472                                              4232   \n",
      "473                                              4736   \n",
      "474                                              3672   \n",
      "475                                              3546   \n",
      "476                                             34352   \n",
      "477                                              8176   \n",
      "478                                              3098   \n",
      "479                                              3788   \n",
      "480                                              5124   \n",
      "481                                              3804   \n",
      "482                                             11328   \n",
      "483                                              3412   \n",
      "484                                              3068   \n",
      "485                                              3996   \n",
      "486                                              3094   \n",
      "487                                              2842   \n",
      "488                                              4876   \n",
      "489                                              2820   \n",
      "490                                              3300   \n",
      "491                                              3502   \n",
      "492                                             10720   \n",
      "493                                              5348   \n",
      "494                                              3230   \n",
      "495                                              2876   \n",
      "496                                              2104   \n",
      "497                                              2388   \n",
      "498                                              2452   \n",
      "\n",
      "     Lifetime People who have liked your Page and engaged with your post  \\\n",
      "0                                                  119                     \n",
      "1                                                 1108                     \n",
      "2                                                  132                     \n",
      "3                                                 1386                     \n",
      "4                                                  396                     \n",
      "5                                                 1016                     \n",
      "6                                                  379                     \n",
      "7                                                  422                     \n",
      "8                                                 1250                     \n",
      "9                                                  199                     \n",
      "10                                                3798                     \n",
      "11                                                 165                     \n",
      "12                                                 152                     \n",
      "13                                                 183                     \n",
      "14                                                 684                     \n",
      "15                                                1162                     \n",
      "16                                                 123                     \n",
      "17                                                1307                     \n",
      "18                                                 101                     \n",
      "19                                                 100                     \n",
      "20                                                 157                     \n",
      "21                                                  15                     \n",
      "22                                                 106                     \n",
      "23                                                 143                     \n",
      "24                                                 995                     \n",
      "25                                                1200                     \n",
      "26                                                1779                     \n",
      "27                                                 166                     \n",
      "28                                                 621                     \n",
      "29                                                 559                     \n",
      "..                                                 ...                     \n",
      "469                                                729                     \n",
      "470                                                392                     \n",
      "471                                                570                     \n",
      "472                                                466                     \n",
      "473                                                576                     \n",
      "474                                                497                     \n",
      "475                                                420                     \n",
      "476                                               2021                     \n",
      "477                                                167                     \n",
      "478                                                483                     \n",
      "479                                                487                     \n",
      "480                                                722                     \n",
      "481                                                 59                     \n",
      "482                                                801                     \n",
      "483                                                453                     \n",
      "484                                                437                     \n",
      "485                                                 58                     \n",
      "486                                                440                     \n",
      "487                                                393                     \n",
      "488                                                660                     \n",
      "489                                                432                     \n",
      "490                                                431                     \n",
      "491                                                437                     \n",
      "492                                                220                     \n",
      "493                                                699                     \n",
      "494                                                422                     \n",
      "495                                                392                     \n",
      "496                                                301                     \n",
      "497                                                363                     \n",
      "498                                                370                     \n",
      "\n",
      "     comment    like  share  Total Interactions  \n",
      "0          4    79.0   17.0                 100  \n",
      "1          5   130.0   29.0                 164  \n",
      "2          0    66.0   14.0                  80  \n",
      "3         58  1572.0  147.0                1777  \n",
      "4         19   325.0   49.0                 393  \n",
      "5          1   152.0   33.0                 186  \n",
      "6          3   249.0   27.0                 279  \n",
      "7          0   325.0   14.0                 339  \n",
      "8          0   161.0   31.0                 192  \n",
      "9          3   113.0   26.0                 142  \n",
      "10         0   233.0   19.0                 252  \n",
      "11         0    88.0   18.0                 106  \n",
      "12         0    90.0   14.0                 104  \n",
      "13         5   137.0   10.0                 152  \n",
      "14         2   577.0   20.0                 599  \n",
      "15         4    86.0   18.0                 108  \n",
      "16         2    40.0   12.0                  54  \n",
      "17        15   678.0   20.0                 713  \n",
      "18         4    54.0   17.0                  75  \n",
      "19         0    34.0    8.0                  42  \n",
      "20         3    66.0   12.0                  81  \n",
      "21         0     0.0    0.0                   0  \n",
      "22         0    16.0    2.0                  18  \n",
      "23         0    72.0   24.0                  96  \n",
      "24         3    99.0   19.0                 121  \n",
      "25         0    88.0   18.0                 106  \n",
      "26        10   412.0   72.0                 494  \n",
      "27         0   100.0   17.0                 117  \n",
      "28        36   523.0   63.0                 622  \n",
      "29        18   143.0   13.0                 174  \n",
      "..       ...     ...    ...                 ...  \n",
      "469       10   193.0   61.0                 264  \n",
      "470        4   114.0   13.0                 131  \n",
      "471        7   160.0   57.0                 224  \n",
      "472        0    46.0   15.0                  61  \n",
      "473        4   136.0   42.0                 182  \n",
      "474        0    73.0   13.0                  86  \n",
      "475        0    65.0   19.0                  84  \n",
      "476        7   579.0   47.0                 633  \n",
      "477        1   101.0    5.0                 107  \n",
      "478        1    74.0   31.0                 106  \n",
      "479        7    84.0   36.0                 127  \n",
      "480       56   360.0   99.0                 515  \n",
      "481        0     5.0    2.0                   7  \n",
      "482        3   187.0   36.0                 226  \n",
      "483        2    69.0   26.0                  97  \n",
      "484        2    82.0   24.0                 108  \n",
      "485        0    12.0    2.0                  14  \n",
      "486        2    56.0   25.0                  83  \n",
      "487        1    44.0   21.0                  66  \n",
      "488       21   277.0   80.0                 378  \n",
      "489        1    74.0   28.0                 103  \n",
      "490        1    79.0   30.0                 110  \n",
      "491        1   105.0   46.0                 152  \n",
      "492        0   128.0    9.0                 137  \n",
      "493       17   185.0   55.0                 257  \n",
      "494       10   125.0   41.0                 176  \n",
      "495        5    53.0   26.0                  84  \n",
      "496        0    53.0   22.0                  75  \n",
      "497        4    93.0   18.0                 115  \n",
      "498        7    91.0   38.0                 136  \n",
      "\n",
      "[495 rows x 19 columns]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page total likes</th>\n",
       "      <th>Type</th>\n",
       "      <th>Category</th>\n",
       "      <th>Post Month</th>\n",
       "      <th>Post Weekday</th>\n",
       "      <th>Post Hour</th>\n",
       "      <th>Paid</th>\n",
       "      <th>Lifetime Post Total Reach</th>\n",
       "      <th>Lifetime Post Total Impressions</th>\n",
       "      <th>Lifetime Engaged Users</th>\n",
       "      <th>Lifetime Post Consumers</th>\n",
       "      <th>Lifetime Post Consumptions</th>\n",
       "      <th>Lifetime Post Impressions by people who have liked your Page</th>\n",
       "      <th>Lifetime Post reach by people who like your Page</th>\n",
       "      <th>Lifetime People who have liked your Page and engaged with your post</th>\n",
       "      <th>comment</th>\n",
       "      <th>like</th>\n",
       "      <th>share</th>\n",
       "      <th>Total Interactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>139441</td>\n",
       "      <td>Photo</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2752</td>\n",
       "      <td>5091</td>\n",
       "      <td>178</td>\n",
       "      <td>109</td>\n",
       "      <td>159</td>\n",
       "      <td>3078</td>\n",
       "      <td>1640</td>\n",
       "      <td>119</td>\n",
       "      <td>4</td>\n",
       "      <td>79.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>139441</td>\n",
       "      <td>Status</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10460</td>\n",
       "      <td>19057</td>\n",
       "      <td>1457</td>\n",
       "      <td>1361</td>\n",
       "      <td>1674</td>\n",
       "      <td>11710</td>\n",
       "      <td>6112</td>\n",
       "      <td>1108</td>\n",
       "      <td>5</td>\n",
       "      <td>130.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>139441</td>\n",
       "      <td>Photo</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2413</td>\n",
       "      <td>4373</td>\n",
       "      <td>177</td>\n",
       "      <td>113</td>\n",
       "      <td>154</td>\n",
       "      <td>2812</td>\n",
       "      <td>1503</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>139441</td>\n",
       "      <td>Photo</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50128</td>\n",
       "      <td>87991</td>\n",
       "      <td>2211</td>\n",
       "      <td>790</td>\n",
       "      <td>1119</td>\n",
       "      <td>61027</td>\n",
       "      <td>32048</td>\n",
       "      <td>1386</td>\n",
       "      <td>58</td>\n",
       "      <td>1572.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>1777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>139441</td>\n",
       "      <td>Photo</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7244</td>\n",
       "      <td>13594</td>\n",
       "      <td>671</td>\n",
       "      <td>410</td>\n",
       "      <td>580</td>\n",
       "      <td>6228</td>\n",
       "      <td>3200</td>\n",
       "      <td>396</td>\n",
       "      <td>19</td>\n",
       "      <td>325.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Page total likes    Type  Category  Post Month  Post Weekday  Post Hour  \\\n",
       "0            139441   Photo         2          12             4          3   \n",
       "1            139441  Status         2          12             3         10   \n",
       "2            139441   Photo         3          12             3          3   \n",
       "3            139441   Photo         2          12             2         10   \n",
       "4            139441   Photo         2          12             2          3   \n",
       "\n",
       "   Paid  Lifetime Post Total Reach  Lifetime Post Total Impressions  \\\n",
       "0   0.0                       2752                             5091   \n",
       "1   0.0                      10460                            19057   \n",
       "2   0.0                       2413                             4373   \n",
       "3   1.0                      50128                            87991   \n",
       "4   0.0                       7244                            13594   \n",
       "\n",
       "   Lifetime Engaged Users  Lifetime Post Consumers  \\\n",
       "0                     178                      109   \n",
       "1                    1457                     1361   \n",
       "2                     177                      113   \n",
       "3                    2211                      790   \n",
       "4                     671                      410   \n",
       "\n",
       "   Lifetime Post Consumptions  \\\n",
       "0                         159   \n",
       "1                        1674   \n",
       "2                         154   \n",
       "3                        1119   \n",
       "4                         580   \n",
       "\n",
       "   Lifetime Post Impressions by people who have liked your Page  \\\n",
       "0                                               3078              \n",
       "1                                              11710              \n",
       "2                                               2812              \n",
       "3                                              61027              \n",
       "4                                               6228              \n",
       "\n",
       "   Lifetime Post reach by people who like your Page  \\\n",
       "0                                              1640   \n",
       "1                                              6112   \n",
       "2                                              1503   \n",
       "3                                             32048   \n",
       "4                                              3200   \n",
       "\n",
       "   Lifetime People who have liked your Page and engaged with your post  \\\n",
       "0                                                119                     \n",
       "1                                               1108                     \n",
       "2                                                132                     \n",
       "3                                               1386                     \n",
       "4                                                396                     \n",
       "\n",
       "   comment    like  share  Total Interactions  \n",
       "0        4    79.0   17.0                 100  \n",
       "1        5   130.0   29.0                 164  \n",
       "2        0    66.0   14.0                  80  \n",
       "3       58  1572.0  147.0                1777  \n",
       "4       19   325.0   49.0                 393  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "print (df.info)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(495, 19)\n"
     ]
    }
   ],
   "source": [
    "print (np.shape(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the Input Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at our input data. We'll use the 7 first columns as our predictors. We'll do the following two things:\n",
    "- Normalize the continuous variables --> you can do this using `np.mean()` and `np.std()`\n",
    "- Make dummy variables of the categorical variables (you can do this by using `pd.get_dummies`)\n",
    "\n",
    "We only count \"Category\" and \"Type\" as categorical variables. Note that you can argue that \"Post month\", \"Post Weekday\" and \"Post Hour\" can also be considered categories, but we'll just treat them as being continuous for now.\n",
    "\n",
    "You'll then use these to define X and Y. \n",
    "\n",
    "To summarize, X will be:\n",
    "* Page total likes\n",
    "* Post Month\n",
    "* Post Weekday\n",
    "* Post Hour\n",
    "* Paid\n",
    "along with dummy variables for:\n",
    "* Type\n",
    "* Category\n",
    "\n",
    "\n",
    "Be sure to normalize your features by subtracting the mean and dividing by the standard deviation.  \n",
    "\n",
    "Finally, y will simply be the \"like\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; define X and y.\n",
    "X0 = df[\"Page total likes\"]\n",
    "X1 = df[\"Type\"]\n",
    "X2 = df[\"Category\"]\n",
    "X3 = df[\"Post Month\"]\n",
    "X4 = df[\"Post Weekday\"]\n",
    "X5 = df[\"Post Hour\"]\n",
    "X6 = df[\"Paid\"]\n",
    "\n",
    "## standardize/categorize\n",
    "X0= (X0-np.mean(X0))/(np.std(X0))\n",
    "dummy_X1= pd.get_dummies(X1)\n",
    "dummy_X2= pd.get_dummies(X2)\n",
    "X3= (X3-np.mean(X3))/(np.std(X3))\n",
    "X4= (X4-np.mean(X4))/(np.std(X4))\n",
    "X5= (X5-np.mean(X5))/(np.std(X5))\n",
    "\n",
    "X = pd.concat([X0, dummy_X1, dummy_X2, X3, X4, X5, X6], axis=1)\n",
    "\n",
    "Y = df[\"like\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is fairly small. Let's just split the data up in a training set and a validation set!  The next three code blocks are all provided for you; have a quick review but not need to make edits!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code provided; defining training and validation sets\n",
    "data_clean = pd.concat([X, Y], axis=1)\n",
    "np.random.seed(123)\n",
    "train, validation = train_test_split(data_clean, test_size=0.2)\n",
    "\n",
    "X_val = validation.iloc[:,0:12]\n",
    "Y_val = validation.iloc[:,12]\n",
    "X_train = train.iloc[:,0:12]\n",
    "Y_train = train.iloc[:,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code provided; building an initial model\n",
    "np.random.seed(123)\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(8, input_dim=12, activation='relu'))\n",
    "model.add(layers.Dense(1, activation = 'linear'))\n",
    "\n",
    "model.compile(optimizer= \"sgd\" ,loss='mse',metrics=['mse'])\n",
    "hist = model.fit(X_train, Y_train, batch_size=32, \n",
    "                 epochs=100, validation_data = (X_val, Y_val), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code provided; previewing the loss through successive epochs\n",
    "hist.history['loss'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you see what happend? all the values for training and validation loss are \"nan\". There could be several reasons for that, but as we already mentioned there is likely a vanishing or exploding gradient problem. recall that we normalized out inputs. But how about the outputs? Let's have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208     54.0\n",
       "290     23.0\n",
       "286     15.0\n",
       "0       79.0\n",
       "401    329.0\n",
       "Name: like, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, indeed. We didn't normalize them and we should, as they take pretty high values. Let\n",
    "s rerun the model but make sure that the output is normalized as well!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing the output\n",
    "\n",
    "Normalize Y as you did X by subtracting the mean and dividing by the standard deviation. Then, resplit the data into training and validation sets as we demonstrated above, and retrain a new model using your normalized X and Y data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here: redefine Y after normalizing the data.\n",
    "Y = (df[\"like\"]-np.mean(df[\"like\"]))/(np.std(df[\"like\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; create training and validation sets as before. Use random seed 123.\n",
    "data_clean = pd.concat([X, Y], axis=1)\n",
    "np.random.seed(123)\n",
    "train, validation = train_test_split(data_clean, test_size=0.2)\n",
    "\n",
    "X_val = validation.iloc[:,0:12]\n",
    "Y_val = validation.iloc[:,12]\n",
    "X_train = train.iloc[:,0:12]\n",
    "Y_train = train.iloc[:,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; rebuild a simple model using a relu layer followed by a linear layer. (See our code snippet above!)\n",
    "np.random.seed(123)\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(8, input_dim=12, activation='relu'))\n",
    "model.add(layers.Dense(1, activation = 'linear'))\n",
    "\n",
    "model.compile(optimizer= \"sgd\" ,loss='mse',metrics=['mse'])\n",
    "hist = model.fit(X_train, Y_train, batch_size=32, \n",
    "                 epochs=100, validation_data = (X_val, Y_val), verbose = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's recheck our loss function. Not only should it be populated with numerical data as opposed to null values, but we also should expect to see the loss function decreasing with successive epochs, demonstrating optimization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.2408857164960918,\n",
       " 1.1754960932514884,\n",
       " 1.135244854622417,\n",
       " 1.10838631487856,\n",
       " 1.09025712070441,\n",
       " 1.0721675779933881,\n",
       " 1.0611902576203298,\n",
       " 1.0505244150908306,\n",
       " 1.0425673209958606,\n",
       " 1.0360943607308648]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history['loss'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We have a converged model. With that, let's investigate how well the model performed with our good old friend, mean squarred error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE_train: 0.9279455578314085\n",
      "MSE_val: 0.9318192922235258\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.predict(X_train).reshape(-1)\n",
    "pred_val = model.predict(X_val).reshape(-1)  \n",
    "\n",
    "MSE_train = np.mean((pred_train-Y_train)**2)\n",
    "MSE_val = np.mean((pred_val-Y_val)**2)\n",
    "\n",
    "print(\"MSE_train:\", MSE_train)\n",
    "print(\"MSE_val:\", MSE_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Weight Initializers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  He Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try and use a weight initializer. In the lecture, we've seen the He normalizer, which initializes the weight vector to have an average 0 and a variance of 2/n, with $n$ the number of features feeding into a layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(8, input_dim=12, kernel_initializer= \"he_normal\",\n",
    "                activation='relu'))\n",
    "model.add(layers.Dense(1, activation = 'linear'))\n",
    "\n",
    "model.compile(optimizer= \"sgd\" ,loss='mse',metrics=['mse'])\n",
    "hist = model.fit(X_train, Y_train, batch_size=32, \n",
    "                 epochs=100, validation_data = (X_val, Y_val),verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = model.predict(X_train).reshape(-1)\n",
    "pred_val = model.predict(X_val).reshape(-1)\n",
    "\n",
    "MSE_train = np.mean((pred_train-Y_train)**2)\n",
    "MSE_val = np.mean((pred_val-Y_val)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9266348367003052\n",
      "0.9474305797782397\n"
     ]
    }
   ],
   "source": [
    "print(MSE_train)\n",
    "print(MSE_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initializer does not really help us to decrease the MSE. We know that initializers can be particularly helpful in deeper networks, and our network isn't very deep. What if we use the `Lecun` initializer with a `tanh` activation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecun Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(8, input_dim=12, \n",
    "                kernel_initializer= \"lecun_normal\", activation='tanh'))\n",
    "model.add(layers.Dense(1, activation = 'linear'))\n",
    "\n",
    "model.compile(optimizer= \"sgd\" ,loss='mse',metrics=['mse'])\n",
    "hist = model.fit(X_train, Y_train, batch_size=32, \n",
    "                 epochs=100, validation_data = (X_val, Y_val), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = model.predict(X_train).reshape(-1)\n",
    "pred_val = model.predict(X_val).reshape(-1)\n",
    "\n",
    "MSE_train = np.mean((pred_train-Y_train)**2)\n",
    "MSE_val = np.mean((pred_val-Y_val)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9274707962315651\n",
      "0.94630185343598\n"
     ]
    }
   ],
   "source": [
    "print(MSE_train)\n",
    "print(MSE_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not much of a difference, but a useful note to consider when tuning your network. Next, let's investigate the impace of various optimization algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(8, input_dim=12, activation='relu'))\n",
    "model.add(layers.Dense(1, activation = 'linear'))\n",
    "\n",
    "model.compile(optimizer= \"rmsprop\" ,loss='mse',metrics=['mse'])\n",
    "hist = model.fit(X_train, Y_train, batch_size=32, \n",
    "                 epochs=100, validation_data = (X_val, Y_val), verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = model.predict(X_train).reshape(-1)\n",
    "pred_val = model.predict(X_val).reshape(-1)\n",
    "\n",
    "MSE_train = np.mean((pred_train-Y_train)**2)\n",
    "MSE_val = np.mean((pred_val-Y_val)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9144420110450608\n",
      "0.9436259458987356\n"
     ]
    }
   ],
   "source": [
    "print(MSE_train)\n",
    "print(MSE_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(8, input_dim=12, activation='relu'))\n",
    "model.add(layers.Dense(1, activation = 'linear'))\n",
    "\n",
    "model.compile(optimizer= \"Adam\" ,loss='mse',metrics=['mse'])\n",
    "hist = model.fit(X_train, Y_train, batch_size=32, \n",
    "                 epochs=100, validation_data = (X_val, Y_val), verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = model.predict(X_train).reshape(-1)\n",
    "pred_val = model.predict(X_val).reshape(-1)\n",
    "\n",
    "MSE_train = np.mean((pred_train-Y_train)**2)\n",
    "MSE_val = np.mean((pred_val-Y_val)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9114025087389569\n",
      "0.9444503989331032\n"
     ]
    }
   ],
   "source": [
    "print(MSE_train)\n",
    "print(MSE_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate Decay with Momentum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "sgd = optimizers.SGD(lr=0.03, decay=0.0001, momentum=0.9)\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(8, input_dim=12, activation='relu'))\n",
    "model.add(layers.Dense(1, activation = 'linear'))\n",
    "\n",
    "model.compile(optimizer= sgd ,loss='mse',metrics=['mse'])\n",
    "hist = model.fit(X_train, Y_train, batch_size=32, \n",
    "                 epochs=100, validation_data = (X_val, Y_val), verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = model.predict(X_train).reshape(-1)\n",
    "pred_val = model.predict(X_val).reshape(-1)\n",
    "\n",
    "MSE_train = np.mean((pred_train-Y_train)**2)\n",
    "MSE_val = np.mean((pred_val-Y_val)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8221831890216236\n",
      "0.9083241245964306\n"
     ]
    }
   ],
   "source": [
    "print(MSE_train)\n",
    "print(MSE_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "* https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Consumer_complaints.ipynb  \n",
    "\n",
    "* https://catalog.data.gov/dataset/consumer-complaint-database  \n",
    "\n",
    "* https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/  \n",
    "\n",
    "* https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/  \n",
    "\n",
    "* https://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/  \n",
    "\n",
    "* https://stackoverflow.com/questions/37232782/nan-loss-when-training-regression-network  \n",
    "\n",
    "* https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary  \n",
    "\n",
    "In this lab, we began to practice some of the concepts regarding normalization and optimization for neural networks. In the final lab for this section, you'll independently practice these concepts on your own in order to tune a model to predict individuals payments to loans."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
